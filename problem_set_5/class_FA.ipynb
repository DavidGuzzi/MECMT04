{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from tabulate import tabulate\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class FA():\n",
    "    \"\"\"\n",
    "    Clase para análisis exploratorio de los Factores de una matriz de datos mediante método de Factores Principales.\n",
    "\n",
    "    Esta clase:\n",
    "        (1) Entrena un modelo de análisis factorial mediante el Método de Factores Principales (\"Principal Factor Method\"), según se define en Rencher (2002, chap. 13);\n",
    "        (2) Devuelve: eigenvalues, eigenvectors, loading matrix, communalities, uniquenesses, correlation matrix;\n",
    "        (3) Permite al generación de una rotación de las cargas (\"orthogonal varimax rotation\").\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    X : np.ndarray\n",
    "        Matriz de datos.\n",
    "    n_factors : int, opcional\n",
    "        Número de factores a extraer.\n",
    "        Default es None.\n",
    "    svd_method : {‘randomized’, 'np.svd'}\n",
    "        Método para la realización de la descomposicón en valores singulares (\"Singular Value Decomposition\").\n",
    "        Default es 'randomized', de librería scikit-learn. Para cualquier otra opción, SVD será realizada desde numpy.\n",
    "\n",
    "    Atributos\n",
    "    ---------\n",
    "    get_eig: :obj:`numpy.ndarray`\n",
    "        Matrices de autovalores y autovectores.\n",
    "    get_loadings: :obj:`numpy.ndarray`\n",
    "        Matriz de cargas.\n",
    "    get_communalities_uniquenesses: :obj:`numpy.ndarray`\n",
    "        Mtrices de comunalidades y unicidades.\n",
    "    get_fa: :obj: personalizado\n",
    "        Salida similiar a STATA.\n",
    "    get_comparative_corr_matrix: :obj: personalizado\n",
    "        Comparación para la matriz de correlaciones (estimada vs. original).\n",
    "    get_rotated_loadings: :obj:`numpy.ndarray`\n",
    "        Cargas rotadas. Permite ajuste Kaiser (None por Default).\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, X, n_factors=None, svd_method=\"randomized\"):\n",
    "        self.X = X\n",
    "        self.n_factors = n_factors\n",
    "        self.svd_method = svd_method\n",
    "\n",
    "    def get_eig(self):\n",
    "        \"\"\" \n",
    "        Regresa los autovalores y autovectores de la matriz de correlación corregida según Método de Factores Principales,\n",
    "        de acuerdo al método de SVD seleccionado. \n",
    "        \"\"\" \n",
    "\n",
    "        self.X_corr = np.corrcoef(self.X, rowvar=False)\n",
    "        self.X_corr_inv = np.linalg.inv(self.X_corr)\n",
    "        self.X_corr_inv_diag = np.diag(self.X_corr_inv)\n",
    "        self.R = 1 - (1 / self.X_corr_inv_diag)\n",
    "        self.X_corr_o = self.X_corr.copy()\n",
    "        np.fill_diagonal(self.X_corr, self.R)\n",
    "        self.eigenvalues, _ = np.linalg.eig(self.X_corr) #Para conocer los autovalores negativos\n",
    "        if self.svd_method == \"randomized_svd\":\n",
    "            self.eigenvectors, self.eigenvalues_p, _ = randomized_svd(self.X_corr, n_components=self.X_corr.shape[1], random_state=1234567890)\n",
    "        else:\n",
    "            self.eigenvectors, self.eigenvalues_p, _ = np.linalg.svd(self.X_corr, full_matrices=False)\n",
    "\n",
    "        return self.eigenvalues, self.eigenvectors\n",
    "\n",
    "    def get_loadings(self):\n",
    "        \"\"\" \n",
    "        Regresa las cargas de los Factores, conservando solo aquellas cargas cuyos autovalores sean positivos.\n",
    "        \"\"\"  \n",
    "\n",
    "        self.get_eig()\n",
    "\n",
    "        self.loadings = self.eigenvectors * np.sqrt(self.eigenvalues_p)\n",
    "        positive_filter = np.array([i for i, value in enumerate(np.round(self.eigenvalues_p, decimals=10)) if value in np.round(self.eigenvalues, decimals=10)])\n",
    "        self.positive_loadings = self.loadings[:, positive_filter]\n",
    "\n",
    "        if self.n_factors == None:\n",
    "            self.positive_loadings\n",
    "        else:\n",
    "            self.positive_loadings = self.positive_loadings[:, :self.n_factors]\n",
    "\n",
    "        return self.positive_loadings\n",
    "    \n",
    "    def get_communalities_uniquenesses(self):\n",
    "        \"\"\" \n",
    "        Regresa las comunalidades y unicidades de los Factores.\n",
    "        \"\"\" \n",
    "\n",
    "        self.get_loadings()\n",
    "        self.communalities, self.uniquenesses = np.sum((self.positive_loadings**2), axis=1), 1 - np.sum((self.positive_loadings**2), axis=1)\n",
    "\n",
    "        return self.communalities, self.uniquenesses\n",
    "        \n",
    "    \n",
    "    def get_fa(self):\n",
    "        \"\"\"\n",
    "        Regresa un resumen detallado de análisis factorial, replicando salida de STATA.\n",
    "        \"\"\"      \n",
    "\n",
    "        self.get_communalities_uniquenesses()                 \n",
    "        loadings_matrix = pd.DataFrame(self.positive_loadings, columns=[f\"Factor {i+1}\" for i in range(self.positive_loadings.shape[1])], index=[f\"x{i+1}\" for i in range(self.positive_loadings.shape[0])]).reset_index(names='Variable')\n",
    "        loadings_matrix = pd.concat([loadings_matrix, pd.DataFrame(self.uniquenesses, columns=['Uniqueness']), pd.DataFrame(self.communalities, columns=['Communality'])], axis=1)\n",
    "        eigenv_matrix = pd.DataFrame(np.sort(self.eigenvalues)[::-1], columns=['Eigenvalue'], index=[f\"Factor {i+1}\" for i in range(self.eigenvalues.shape[0])]).reset_index(names='Factor')\n",
    "        eigenv_proportion = [np.sort(self.eigenvalues)[::-1][i] / np.sum(np.sort(self.eigenvalues)[::-1]) for i in range(len(self.eigenvalues))]\n",
    "        eigenv_proportion_cs = np.cumsum(eigenv_proportion)\n",
    "        eigenv_matrix = pd.concat([eigenv_matrix, pd.DataFrame(eigenv_proportion, columns=['Proportion']), pd.DataFrame(eigenv_proportion_cs, columns=['Cumulative'])], axis=1)\n",
    "\n",
    "        eigenv_table = tabulate(eigenv_matrix, headers='keys', tablefmt=\"fancy_grid\", showindex=False, floatfmt=\".4f\")\n",
    "        loadings_table = tabulate(loadings_matrix, headers='keys', tablefmt=\"fancy_grid\", showindex=False, floatfmt=\".4f\")\n",
    "\n",
    "        eigenv_lines = eigenv_table.splitlines()\n",
    "        loadings_lines = loadings_table.splitlines()\n",
    "\n",
    "        max_lines = max(len(eigenv_lines), len(loadings_lines))\n",
    "        eigenv_lines += [''] * (max_lines - len(eigenv_lines))\n",
    "        loadings_lines += [''] * (max_lines - len(loadings_lines))\n",
    "\n",
    "        combined_output = \"\\n\".join(f\"{eigenv: <40}   {loading}\" for eigenv, loading in zip(eigenv_lines, loadings_lines))\n",
    "        \n",
    "        print(\"Resultados de Factor Analysis\")\n",
    "        print(combined_output)\n",
    "    \n",
    "    def get_comparative_corr_matrix(self):\n",
    "        \"\"\"\n",
    "        Regresa una comparación de la matriz de correlaciones (estimada por el modelo factorial vs. original).\n",
    "        \"\"\"\n",
    "        self.get_communalities_uniquenesses()\n",
    "        estimated_corr = self.positive_loadings @ self.positive_loadings.T + np.diag(self.uniquenesses)\n",
    "        estimated_corr_matrix = pd.DataFrame(estimated_corr, columns=[f\"x{i+1}\" for i in range(estimated_corr.shape[1])], index=[f\"x{i+1}\" for i in range(estimated_corr.shape[0])]).reset_index(names='Variables')\n",
    "        corr = self.X_corr_o\n",
    "        corr_matrix = pd.DataFrame(corr, columns=[f\"x{i+1}\" for i in range(corr.shape[1])], index=[f\"x{i+1}\" for i in range(corr.shape[0])]).reset_index(names='Variables')\n",
    "\n",
    "        est_corr_table = tabulate(estimated_corr_matrix, headers='keys', tablefmt=\"fancy_grid\", showindex=False, floatfmt=\".4f\")\n",
    "        corr_table = tabulate(corr_matrix, headers='keys', tablefmt=\"fancy_grid\", showindex=False, floatfmt=\".4f\")\n",
    "\n",
    "        est_corr_lines = est_corr_table.splitlines()\n",
    "        corr_lines = corr_table.splitlines()\n",
    "\n",
    "        max_lines = max(len(est_corr_lines), len(corr_lines))\n",
    "        est_corr_lines += [''] * (max_lines - len(est_corr_lines))\n",
    "        corr_lines += [''] * (max_lines - len(corr_lines))\n",
    "\n",
    "        combined_output = \"\\n\".join(f\"{eigenv: <40}   {loading}\" for eigenv, loading in zip(est_corr_lines, corr_lines))\n",
    "     \n",
    "\n",
    "        print(\"Matriz de correlación estimada (izquierda) vs. Matriz de correlación (derecha)\")\n",
    "        print(combined_output)\n",
    "        \n",
    "\n",
    "    def get_rotated_loadings(self, kaiser=False):\n",
    "        \"\"\"\n",
    "        Regresa la cargas rotadas del modelo factorial (orthogonal varimax rotation\").\n",
    "        Permite aplicar adecuación Kaiser.\n",
    "        \"\"\"\n",
    "        self.get_communalities_uniquenesses()\n",
    "        X = self.positive_loadings.copy()\n",
    "        n_rows, n_cols = X.shape\n",
    "        if n_cols < 2:\n",
    "            return X\n",
    "\n",
    "        # normalize the loadings matrix\n",
    "        # using sqrt of the sum of squares (Kaiser)\n",
    "        if kaiser:\n",
    "            normalized_mtx = np.apply_along_axis(\n",
    "                lambda x: np.sqrt(np.sum(x**2)), 1, X.copy()\n",
    "            )\n",
    "            X = (X.T / normalized_mtx).T\n",
    "\n",
    "        # initialize the rotation matrix\n",
    "        # to N x N identity matrix\n",
    "        rotation_mtx = np.eye(n_cols)\n",
    "\n",
    "        d = 0\n",
    "        for _ in range(5000):\n",
    "            old_d = d\n",
    "\n",
    "            # take inner product of loading matrix\n",
    "            # and rotation matrix\n",
    "            basis = np.dot(X, rotation_mtx)\n",
    "\n",
    "            # transform data for singular value decomposition using updated formula :\n",
    "            # B <- t(x) %*% (z^3 - z %*% diag(drop(rep(1, p) %*% z^2))/p)\n",
    "            diagonal = np.diag(np.squeeze(np.repeat(1, n_rows).dot(basis**2)))\n",
    "            transformed = X.T.dot(basis**3 - basis.dot(diagonal) / n_rows)\n",
    "\n",
    "            # perform SVD on\n",
    "            # the transformed matrix\n",
    "            U, S, V = np.linalg.svd(transformed)\n",
    "\n",
    "            # take inner product of U and V, and sum of S\n",
    "            rotation_mtx = np.dot(U, V)\n",
    "            d = np.sum(S)\n",
    "\n",
    "            # check convergence\n",
    "            if d < old_d * (1 + 1e-5):\n",
    "                break\n",
    "\n",
    "        # take inner product of loading matrix\n",
    "        # and rotation matrix\n",
    "        X = np.dot(X, rotation_mtx)\n",
    "\n",
    "        # de-normalize the data\n",
    "        if kaiser:\n",
    "            X = X.T * normalized_mtx\n",
    "        else:\n",
    "            X = X.T\n",
    "\n",
    "        # convert loadings matrix to data frame\n",
    "        rotated_loadings = X.T.copy()\n",
    "        return rotated_loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.read_excel(r\"C:\\Users\\HP\\OneDrive\\Escritorio\\David Guzzi\\Github\\MECMT04\\TP AEM - database.xlsx\")\n",
    "\n",
    "final.columns = [f\"X{i}\" for i in range(len(final.columns))]\n",
    "final = final.iloc[:,2:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054495</td>\n",
       "      <td>-0.734506</td>\n",
       "      <td>0.139047</td>\n",
       "      <td>0.084986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.197313</td>\n",
       "      <td>-0.783663</td>\n",
       "      <td>-0.228598</td>\n",
       "      <td>0.024281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.208433</td>\n",
       "      <td>0.330184</td>\n",
       "      <td>-0.471200</td>\n",
       "      <td>-0.298080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.037655</td>\n",
       "      <td>-0.173268</td>\n",
       "      <td>-0.709790</td>\n",
       "      <td>0.067278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.875801</td>\n",
       "      <td>0.124088</td>\n",
       "      <td>-0.071768</td>\n",
       "      <td>-0.188519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.879000</td>\n",
       "      <td>0.002539</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.170965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.063678</td>\n",
       "      <td>-0.158350</td>\n",
       "      <td>-0.265593</td>\n",
       "      <td>0.370071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0  0.054495 -0.734506  0.139047  0.084986\n",
       "1 -0.197313 -0.783663 -0.228598  0.024281\n",
       "2  0.208433  0.330184 -0.471200 -0.298080\n",
       "3  0.037655 -0.173268 -0.709790  0.067278\n",
       "4  0.875801  0.124088 -0.071768 -0.188519\n",
       "5  0.879000  0.002539  0.000013  0.170965\n",
       "6  0.063678 -0.158350 -0.265593  0.370071"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa = FA(final)\n",
    "pd.DataFrame(fa.get_rotated_loadings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6\n",
      "0  1.000000  0.535130 -0.322015  0.036342 -0.069417  0.060567  0.114300\n",
      "1  0.535130  1.000000 -0.199402  0.292244 -0.258222 -0.171280  0.181228\n",
      "2 -0.322015 -0.199402  1.000000  0.265037  0.313529  0.133084 -0.024176\n",
      "3  0.036342  0.292244  0.265037  1.000000  0.049735  0.044152  0.243248\n",
      "4 -0.069417 -0.258222  0.313529  0.049735  1.000000  0.737913 -0.014584\n",
      "5  0.060567 -0.171280  0.133084  0.044152  0.737913  1.000000  0.118837\n",
      "6  0.114300  0.181228 -0.024176  0.243248 -0.014584  0.118837  1.000000           0         1             2         3             4             5  \\\n",
      "0  0.000000  0.071771  1.411969e-02 -0.058105  9.864752e-03  6.853152e-03   \n",
      "1  0.071771  0.000000 -3.544898e-02  0.081438  5.884523e-03 -2.295594e-02   \n",
      "2  0.014120 -0.035449 -1.110223e-16  0.045048  4.192798e-02 -4.048848e-02   \n",
      "3 -0.058105  0.081438  4.504802e-02  0.000000 -7.879195e-03  1.927687e-02   \n",
      "4  0.009865  0.005885  4.192798e-02 -0.007879 -1.110223e-16  6.487921e-02   \n",
      "5  0.006853 -0.022956 -4.048848e-02  0.019277  6.487921e-02 -2.220446e-16   \n",
      "6  0.033328 -0.040252 -8.003081e-03  0.046670 -3.388416e-02  2.612708e-02   \n",
      "\n",
      "          6  \n",
      "0  0.033328  \n",
      "1 -0.040252  \n",
      "2 -0.008003  \n",
      "3  0.046670  \n",
      "4 -0.033884  \n",
      "5  0.026127  \n",
      "6  0.000000  \n"
     ]
    }
   ],
   "source": [
    "fa.get_estimated_corr_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(          0         1         2         3\n",
       " 0  0.054495  0.734506 -0.139047  0.084986\n",
       " 1 -0.197313  0.783663  0.228598  0.024281\n",
       " 2  0.208433 -0.330184  0.471200 -0.298080\n",
       " 3  0.037655  0.173268  0.709790  0.067278\n",
       " 4  0.875801 -0.124088  0.071768 -0.188519\n",
       " 5  0.879000 -0.002539 -0.000013  0.170965\n",
       " 6  0.063678  0.158350  0.265593  0.370071,\n",
       "           0         1         2         3\n",
       " 0  0.838151 -0.523330  0.092727 -0.122597\n",
       " 1  0.481565  0.785763  0.336851  0.192881\n",
       " 2 -0.255311 -0.216087  0.935279 -0.115654\n",
       " 3 -0.020336 -0.249017  0.056448  0.966639)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa.get_rotated_loadings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
