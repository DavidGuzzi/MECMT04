{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from tabulate import tabulate\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class FA():\n",
    "    \"\"\"\n",
    "    Clase para la obtención de los Factores de una matriz de datos mediante método de Factores Principales.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_factors=None, svd_method=\"randomized\"):\n",
    "        self.n_factors = n_factors\n",
    "        self.svd_method = svd_method\n",
    "\n",
    "    def loadings(self, X, n_factors = None):\n",
    "        \"\"\"\n",
    "        Returns the loading matrix of the specified number of principal components.\n",
    "        If not specified retuns for all the components whose Eigen value greater than 0\n",
    "        \"\"\"\n",
    "        self.X_corr = np.corrcoef(X, rowvar=False)\n",
    "        self.X_corr_inv = np.linalg.inv(self.X_corr)\n",
    "        self.X_corr_inv_diag = np.diag(self.X_corr_inv)\n",
    "        self.R = 1 - (1 / self.X_corr_inv_diag)\n",
    "        self.X_corr_o = self.X_corr.copy()\n",
    "        np.fill_diagonal(self.X_corr, self.R)\n",
    "        self.eigenvalues, _ = np.linalg.eig(self.X_corr)\n",
    "        #agregar la otra opción. \n",
    "        self.eigenvectors, self.eigenvalues_p, _ = randomized_svd(self.X_corr, n_components=self.X_corr.shape[1], random_state=1234567890)     \n",
    "        \n",
    "        self.loadings = self.eigenvectors * np.sqrt(self.eigenvalues_p)\n",
    "        positive_filter = np.array([i for i, value in enumerate(np.round(self.eigenvalues_p, decimals=10)) if value in np.round(self.eigenvalues, decimals=10)])\n",
    "        self.postive_loadings = self.loadings[:, positive_filter]\n",
    "\n",
    "        if n_factors == None:\n",
    "            self.postive_loadings\n",
    "        else:\n",
    "            self.postive_loadings = self.postive_loadings[:, :n_factors]\n",
    "                    \n",
    "        loadings_matrix = pd.DataFrame(self.postive_loadings, columns=[f\"Factor {i+1}\" for i in range(self.postive_loadings.shape[1])], index=[f\"x{i+1}\" for i in range(self.postive_loadings.shape[0])]).reset_index(names='Variable')\n",
    "        self.communalities, self.uniquenesses = np.sum((self.postive_loadings**2), axis=1), 1 - np.sum((self.postive_loadings**2), axis=1)\n",
    "        loadings_matrix = pd.concat([loadings_matrix, pd.DataFrame(self.uniquenesses, columns=['Uniqueness']), pd.DataFrame(self.communalities, columns=['Communality'])], axis=1)\n",
    "        eigenv_matrix = pd.DataFrame(np.sort(self.eigenvalues)[::-1], columns=['Eigenvalue'], index=[f\"Factor {i+1}\" for i in range(self.eigenvalues.shape[0])]).reset_index(names='Factor')\n",
    "        eigenv_proportion = [np.sort(self.eigenvalues)[::-1][i] / np.sum(np.sort(self.eigenvalues)[::-1]) for i in range(len(self.eigenvalues))]\n",
    "        eigenv_proportion_cs = np.cumsum(eigenv_proportion)\n",
    "        eigenv_matrix = pd.concat([eigenv_matrix, pd.DataFrame(eigenv_proportion, columns=['Proportion']), pd.DataFrame(eigenv_proportion_cs, columns=['Cumulative'])], axis=1)\n",
    "\n",
    "        # print(f\"-------------Resultados de Factor Analysis-------------\")\n",
    "        # print(tabulate(eigenv_matrix, headers='keys', tablefmt=\"fancy_grid\", showindex=False, floatfmt=\".4f\"))\n",
    "        # print(f\"-------------------------------------------------------\")\n",
    "        # print(tabulate(loadings_matrix, headers='keys', tablefmt=\"fancy_grid\", showindex=False, floatfmt=\".4f\"))\n",
    "        # Definir las tablas como cadenas\n",
    "        eigenv_table = tabulate(eigenv_matrix, headers='keys', tablefmt=\"fancy_grid\", showindex=False, floatfmt=\".4f\")\n",
    "        loadings_table = tabulate(loadings_matrix, headers='keys', tablefmt=\"fancy_grid\", showindex=False, floatfmt=\".4f\")\n",
    "\n",
    "        # Separar las líneas de cada tabla\n",
    "        eigenv_lines = eigenv_table.splitlines()\n",
    "        loadings_lines = loadings_table.splitlines()\n",
    "\n",
    "        # Asegurarse de que ambas tengan la misma cantidad de líneas\n",
    "        max_lines = max(len(eigenv_lines), len(loadings_lines))\n",
    "        eigenv_lines += [''] * (max_lines - len(eigenv_lines))\n",
    "        loadings_lines += [''] * (max_lines - len(loadings_lines))\n",
    "\n",
    "        # Combinar ambas tablas en una sola salida\n",
    "        combined_output = \"\\n\".join(f\"{eigenv: <40}   {loading}\" for eigenv, loading in zip(eigenv_lines, loadings_lines))\n",
    "        bold_start = \"\\033[1m\"\n",
    "        bold_end = \"\\033[0m\"\n",
    "        # Imprimir el resultado\n",
    "        print(f\"{bold_start}Resultados de Factor Analysis{bold_end}\")\n",
    "        print(combined_output)\n",
    "\n",
    "    def get_est_corr_matrix(self):\n",
    "        \"\"\"\n",
    "        Returns the estimated correlated matrix of X, and the differrences with original correlated matrix of X\n",
    "        \"\"\"\n",
    "        ee = pd.DataFrame(self.postive_loadings @ self.postive_loadings.T + np.diag(self.uniquenesses))\n",
    "        \n",
    "        print(ee, pd.DataFrame(self.X_corr_o)-ee)\n",
    "\n",
    "    # def varimaxr(self, loadings, normalize = True, max_iter = 500, tolerance = 1e-5):\n",
    "    #     df = loadings.copy()\n",
    "    #     column_names = df.index.values\n",
    "    #     index_names = df.columns.values\n",
    "    #     n_rows, n_cols = df.shape\n",
    "    #     if n_cols < 2:\n",
    "    #         return df\n",
    "    #     X = df.values\n",
    "    #     if normalize:\n",
    "    #         normalized_mtx = df.apply(lambda x: np.sqrt(sum(x**2)),\n",
    "    #                                   axis=1).values\n",
    "    #         X = (X.T / normalized_mtx).T\n",
    "    #     rotation_mtx = np.eye(n_cols)\n",
    "\n",
    "    #     d = 0\n",
    "    #     for _ in range(max_iter):\n",
    "    #         old_d = d\n",
    "    #         basis = np.dot(X, rotation_mtx)\n",
    "    #         transformed = np.dot(X.T, basis**3 - (1.0 / n_rows) *\n",
    "    #                              np.dot(basis, np.diag(np.diag(np.dot(basis.T, basis)))))\n",
    "    #         U, S, V = np.linalg.svd(transformed)\n",
    "    #         rotation_mtx = np.dot(U, V)\n",
    "    #         d = np.sum(S)\n",
    "    #         if old_d != 0 and d / old_d < 1 + tolerance:\n",
    "    #             break\n",
    "\n",
    "    #     X = np.dot(X, rotation_mtx)\n",
    "\n",
    "    #     if normalize:\n",
    "    #         X = X.T * normalized_mtx\n",
    "    #     else:\n",
    "    #         X = X.T\n",
    "    #     loadings = pd.DataFrame(X, columns=column_names, index=index_names).T\n",
    "\n",
    "    #     def flip_sign(vec):\n",
    "    #         for i in range(vec.shape[1]):\n",
    "    #             if(vec[:, i].sum() < 0):\n",
    "    #                 vec[:, i] = -1 * vec[:, i]\n",
    "    #         return vec\n",
    "\n",
    "    #     rloadnpmat = loadings.as_matrix()\n",
    "    #     rloadingflip = flip_sign(rloadnpmat)\n",
    "\n",
    "    #     def matx(mat):\n",
    "    #         rpe = mat ** 2\n",
    "    #         rpesum = np.sum(rpe, axis = 0)\n",
    "    #         ind = rpesum.argsort()\n",
    "    #         rr = mat[:, ind]\n",
    "    #         return rr\n",
    "        \n",
    "    #     index  = [\"PC\"+str(i) for i in range(loadings.shape[1])]\n",
    "    #     varmaxrotmat = pd.DataFrame(matx(rloadingflip), columns = index)\n",
    "        \n",
    "    #     return varmaxrotmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.read_excel(r\"C:\\Users\\HP\\OneDrive\\Escritorio\\David Guzzi\\Github\\MECMT04\\TP AEM - database.xlsx\")\n",
    "\n",
    "final.columns = [f\"X{i}\" for i in range(len(final.columns))]\n",
    "final = final.iloc[:,2:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mResultados de Factor Analysis\u001b[0m\n",
      "╒══════════╤══════════════╤══════════════╤══════════════╕   ╒════════════╤════════════╤════════════╤════════════╤════════════╤══════════════╤═══════════════╕\n",
      "│ Factor   │   Eigenvalue │   Proportion │   Cumulative │   │ Variable   │   Factor 1 │   Factor 2 │   Factor 3 │   Factor 4 │   Uniqueness │   Communality │\n",
      "╞══════════╪══════════════╪══════════════╪══════════════╡   ╞════════════╪════════════╪════════════╪════════════╪════════════╪══════════════╪═══════════════╡\n",
      "│ Factor 1 │       1.8282 │       0.4982 │       0.4982 │   │ x1         │    -0.3620 │     0.5729 │    -0.3125 │    -0.1097 │       0.4310 │        0.5690 │\n",
      "├──────────┼──────────────┼──────────────┼──────────────┤   ├────────────┼────────────┼────────────┼────────────┼────────────┼──────────────┼───────────────┤\n",
      "│ Factor 2 │       1.2632 │       0.3442 │       0.8424 │   │ x2         │    -0.5573 │     0.6024 │     0.0920 │    -0.1548 │       0.2941 │        0.7059 │\n",
      "├──────────┼──────────────┼──────────────┼──────────────┤   ├────────────┼────────────┼────────────┼────────────┼────────────┼──────────────┼───────────────┤\n",
      "│ Factor 3 │       0.8155 │       0.2222 │       1.0646 │   │ x3         │     0.4277 │    -0.0578 │     0.4933 │    -0.1836 │       0.5367 │        0.4633 │\n",
      "├──────────┼──────────────┼──────────────┼──────────────┤   ├────────────┼────────────┼────────────┼────────────┼────────────┼──────────────┼───────────────┤\n",
      "│ Factor 4 │       0.2328 │       0.0634 │       1.1281 │   │ x4         │    -0.0015 │     0.4064 │     0.6090 │     0.0612 │       0.4602 │        0.5398 │\n",
      "├──────────┼──────────────┼──────────────┼──────────────┤   ├────────────┼────────────┼────────────┼────────────┼────────────┼──────────────┼───────────────┤\n",
      "│ Factor 5 │      -0.0323 │      -0.0088 │       1.1193 │   │ x5         │     0.8288 │     0.3121 │    -0.1079 │    -0.1651 │       0.1769 │        0.8231 │\n",
      "├──────────┼──────────────┼──────────────┼──────────────┤   ├────────────┼────────────┼────────────┼────────────┼────────────┼──────────────┼───────────────┤\n",
      "│ Factor 6 │      -0.1703 │      -0.0464 │       1.0729 │   │ x6         │     0.7171 │     0.4543 │    -0.2437 │     0.1480 │       0.1981 │        0.8019 │\n",
      "├──────────┼──────────────┼──────────────┼──────────────┤   ├────────────┼────────────┼────────────┼────────────┼────────────┼──────────────┼───────────────┤\n",
      "│ Factor 7 │      -0.2674 │      -0.0729 │       1.0000 │   │ x7         │    -0.0502 │     0.3159 │     0.1551 │     0.3320 │       0.7634 │        0.2366 │\n",
      "╘══════════╧══════════════╧══════════════╧══════════════╛   ╘════════════╧════════════╧════════════╧════════════╧════════════╧══════════════╧═══════════════╛\n"
     ]
    }
   ],
   "source": [
    "fa = FA()\n",
    "fa.loadings(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6\n",
      "0  1.000000  0.535130 -0.322015  0.036342 -0.069417  0.060567  0.114300\n",
      "1  0.535130  1.000000 -0.199402  0.292244 -0.258222 -0.171280  0.181228\n",
      "2 -0.322015 -0.199402  1.000000  0.265037  0.313529  0.133084 -0.024176\n",
      "3  0.036342  0.292244  0.265037  1.000000  0.049735  0.044152  0.243248\n",
      "4 -0.069417 -0.258222  0.313529  0.049735  1.000000  0.737913 -0.014584\n",
      "5  0.060567 -0.171280  0.133084  0.044152  0.737913  1.000000  0.118837\n",
      "6  0.114300  0.181228 -0.024176  0.243248 -0.014584  0.118837  1.000000           0         1             2         3             4             5  \\\n",
      "0  0.000000  0.071771  1.411969e-02 -0.058105  9.864752e-03  6.853152e-03   \n",
      "1  0.071771  0.000000 -3.544898e-02  0.081438  5.884523e-03 -2.295594e-02   \n",
      "2  0.014120 -0.035449 -1.110223e-16  0.045048  4.192798e-02 -4.048848e-02   \n",
      "3 -0.058105  0.081438  4.504802e-02  0.000000 -7.879195e-03  1.927687e-02   \n",
      "4  0.009865  0.005885  4.192798e-02 -0.007879 -1.110223e-16  6.487921e-02   \n",
      "5  0.006853 -0.022956 -4.048848e-02  0.019277  6.487921e-02 -2.220446e-16   \n",
      "6  0.033328 -0.040252 -8.003081e-03  0.046670 -3.388416e-02  2.612708e-02   \n",
      "\n",
      "          6  \n",
      "0  0.033328  \n",
      "1 -0.040252  \n",
      "2 -0.008003  \n",
      "3  0.046670  \n",
      "4 -0.033884  \n",
      "5  0.026127  \n",
      "6  0.000000  \n"
     ]
    }
   ],
   "source": [
    "fa.get_est_corr_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
